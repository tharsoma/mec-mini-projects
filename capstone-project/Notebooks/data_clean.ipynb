{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c56e93c-5603-4707-9b07-504e0f616562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "path_to_json = 'Data/AAPL'\n",
    "json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c17d10-d471-44bd-b743-283fc540af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',100)\n",
    "pd.set_option('display.max_rows',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "20c00332-c636-4db7-a18d-e9e7b7c963bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_all_json_data(folderPath: str, list_of_jsons) -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    for element in list_of_jsons:\n",
    "        full_path = folderPath+\"/\"+element\n",
    "        #print (full_path)\n",
    "        \n",
    "        \n",
    "        df = df.append(pd.read_json(full_path))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20809d2c-6e09-47d4-afa6-886d2ccf0115",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['id', 'body', 'created_at', 'user', 'source', 'symbols', 'conversation',\n       'likes', 'mentioned_users', 'entities', 'links', 'reshares'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-d851796b9791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappend_all_json_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_to_json\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjson_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-7c520efd548e>\u001b[0m in \u001b[0;36mappend_all_json_data\u001b[1;34m(folderPath, list_of_jsons)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mfull_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolderPath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print (full_path)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8108\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8109\u001b[0m         \"\"\"\n\u001b[1;32m-> 8110\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   8111\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8112\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8133\u001b[0m                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8134\u001b[0m                 )\n\u001b[1;32m-> 8135\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   8136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8137\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[0;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2178\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['id', 'body', 'created_at', 'user', 'source', 'symbols', 'conversation',\n       'likes', 'mentioned_users', 'entities', 'links', 'reshares'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "nd = append_all_json_data(path_to_json,json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96da9b7a-d7bd-4597-9566-7700d2275685",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-384e999bf8ac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-384e999bf8ac>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    new_dataframe = nd.filter(['created_at','body','['user']['username'])\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "new_dataframe = nd.filter(['created_at','body','['user']['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b19b28-160e-4c39-a3ea-e39989cadd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-01-26 19:46:52+00:00</td>\n",
       "      <td>$AAPL Treasury ripping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-01-26 19:46:42+00:00</td>\n",
       "      <td>$AAPL where dying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-01-26 19:46:36+00:00</td>\n",
       "      <td>$AAPL 155 anyone hello?bulls?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-01-26 19:46:32+00:00</td>\n",
       "      <td>$AAPL hahaha what morons we live with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-01-26 19:46:26+00:00</td>\n",
       "      <td>$AAPL rate hike imminent! tech getting slaughtered! YEEHAW!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-01-26 19:46:16+00:00</td>\n",
       "      <td>$AAPL gonna fall a few more bucks after hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-01-26 19:46:10+00:00</td>\n",
       "      <td>$AAPL OI BOIII BOO BOO THE FOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-01-26 19:46:10+00:00</td>\n",
       "      <td>$Aapl was short 3x $147 puts (actually short over 25 puts lmfao) , and i covered. Shorted $146 puts for higher than what i covered the 147s at and this is a W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-01-26 19:46:04+00:00</td>\n",
       "      <td>$AAPL 155 anyone..?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-01-26 19:45:48+00:00</td>\n",
       "      <td>$AAPL WTF just caused that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "20 2022-01-26 19:46:52+00:00   \n",
       "21 2022-01-26 19:46:42+00:00   \n",
       "22 2022-01-26 19:46:36+00:00   \n",
       "23 2022-01-26 19:46:32+00:00   \n",
       "24 2022-01-26 19:46:26+00:00   \n",
       "25 2022-01-26 19:46:16+00:00   \n",
       "26 2022-01-26 19:46:10+00:00   \n",
       "27 2022-01-26 19:46:10+00:00   \n",
       "28 2022-01-26 19:46:04+00:00   \n",
       "29 2022-01-26 19:45:48+00:00   \n",
       "\n",
       "                                                                                                                                                              body  \n",
       "20                                                                                                                                          $AAPL Treasury ripping  \n",
       "21                                                                                                                                               $AAPL where dying  \n",
       "22                                                                                                                                   $AAPL 155 anyone hello?bulls?  \n",
       "23                                                                                                                           $AAPL hahaha what morons we live with  \n",
       "24                                                                                                     $AAPL rate hike imminent! tech getting slaughtered! YEEHAW!  \n",
       "25                                                                                                                   $AAPL gonna fall a few more bucks after hours  \n",
       "26                                                                                                                                  $AAPL OI BOIII BOO BOO THE FOO  \n",
       "27  $Aapl was short 3x $147 puts (actually short over 25 puts lmfao) , and i covered. Shorted $146 puts for higher than what i covered the 147s at and this is a W  \n",
       "28                                                                                                                                             $AAPL 155 anyone..?  \n",
       "29                                                                                                                                      $AAPL WTF just caused that  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76b320b1-f2d9-4efd-a6d9-89cfbc6fd59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08442831-dc98-4b95-a7ca-7f323a9726d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9863edf2-e283-44aa-8b2d-0b87da3fe83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json = pd.read_json('Data/AAPL/401854269.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "86b7a4a9-7a7d-46f8-999d-5068af7f7d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   id               30 non-null     int64              \n",
      " 1   body             30 non-null     object             \n",
      " 2   created_at       30 non-null     datetime64[ns, UTC]\n",
      " 3   user             30 non-null     object             \n",
      " 4   source           30 non-null     object             \n",
      " 5   symbols          30 non-null     object             \n",
      " 6   conversation     8 non-null      object             \n",
      " 7   likes            24 non-null     object             \n",
      " 8   mentioned_users  30 non-null     object             \n",
      " 9   entities         30 non-null     object             \n",
      " 10  links            12 non-null     object             \n",
      " 11  reshare_message  1 non-null      object             \n",
      " 12  reshares         1 non-null      object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(11)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "new_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fdd83f1-7890-455d-97ce-758f24a0f9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bullish'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json[\"entities\"][2][\"sentiment\"][\"basic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e9d2e9-2d03-4776-944d-69d35f05b95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "af205758-6e67-48ab-89ec-440d9e2e1ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe544b9c-fbbf-4d0c-878f-15d8fe88babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"username\"] = new_json[\"user\"][0][\"username\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca18afb-adec-49a3-a54c-558153fc159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "appl = yf.Ticker(\"AAPL\")\n",
    "hist = appl.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50646218-348b-4772-9632-4effd93ac606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    x = round(hist.loc['2021-11-6'].Close,3)\n",
    "except KeyError:\n",
    "    x = 4\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23025c46-c8d7-4991-814d-e5c0275f5216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.100323</td>\n",
       "      <td>0.100759</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>0.100323</td>\n",
       "      <td>469033600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.095525</td>\n",
       "      <td>0.095525</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>0.095089</td>\n",
       "      <td>175884800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.088546</td>\n",
       "      <td>0.088546</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>105728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.090291</td>\n",
       "      <td>0.090727</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>0.090291</td>\n",
       "      <td>86441600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.092908</td>\n",
       "      <td>0.093345</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>73449600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-19</th>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.099015</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>48630400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-22</th>\n",
       "      <td>0.103376</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>0.103376</td>\n",
       "      <td>37363200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-23</th>\n",
       "      <td>0.107739</td>\n",
       "      <td>0.108175</td>\n",
       "      <td>0.107739</td>\n",
       "      <td>0.107739</td>\n",
       "      <td>46950400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-24</th>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.113845</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>48003200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-26</th>\n",
       "      <td>0.123877</td>\n",
       "      <td>0.124314</td>\n",
       "      <td>0.123877</td>\n",
       "      <td>0.123877</td>\n",
       "      <td>55574400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-29</th>\n",
       "      <td>0.125622</td>\n",
       "      <td>0.126058</td>\n",
       "      <td>0.125622</td>\n",
       "      <td>0.125622</td>\n",
       "      <td>93161600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-30</th>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.123005</td>\n",
       "      <td>0.122569</td>\n",
       "      <td>0.122569</td>\n",
       "      <td>68880000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-31</th>\n",
       "      <td>0.119516</td>\n",
       "      <td>0.119516</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>35750400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>0.120388</td>\n",
       "      <td>0.121260</td>\n",
       "      <td>0.120388</td>\n",
       "      <td>0.120388</td>\n",
       "      <td>21660800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>0.118207</td>\n",
       "      <td>0.118207</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>0.117771</td>\n",
       "      <td>35728000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-06</th>\n",
       "      <td>0.112973</td>\n",
       "      <td>0.112973</td>\n",
       "      <td>0.112536</td>\n",
       "      <td>0.112536</td>\n",
       "      <td>45158400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-07</th>\n",
       "      <td>0.108175</td>\n",
       "      <td>0.108175</td>\n",
       "      <td>0.107739</td>\n",
       "      <td>0.107739</td>\n",
       "      <td>55686400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-08</th>\n",
       "      <td>0.105994</td>\n",
       "      <td>0.105994</td>\n",
       "      <td>0.105558</td>\n",
       "      <td>0.105558</td>\n",
       "      <td>39827200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-09</th>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.111664</td>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.111228</td>\n",
       "      <td>21504000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-12</th>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.111228</td>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.110356</td>\n",
       "      <td>23699200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close     Volume  Dividends  \\\n",
       "Date                                                                       \n",
       "1980-12-12  0.100323  0.100759  0.100323  0.100323  469033600        0.0   \n",
       "1980-12-15  0.095525  0.095525  0.095089  0.095089  175884800        0.0   \n",
       "1980-12-16  0.088546  0.088546  0.088110  0.088110  105728000        0.0   \n",
       "1980-12-17  0.090291  0.090727  0.090291  0.090291   86441600        0.0   \n",
       "1980-12-18  0.092908  0.093345  0.092908  0.092908   73449600        0.0   \n",
       "1980-12-19  0.098578  0.099015  0.098578  0.098578   48630400        0.0   \n",
       "1980-12-22  0.103376  0.103813  0.103376  0.103376   37363200        0.0   \n",
       "1980-12-23  0.107739  0.108175  0.107739  0.107739   46950400        0.0   \n",
       "1980-12-24  0.113409  0.113845  0.113409  0.113409   48003200        0.0   \n",
       "1980-12-26  0.123877  0.124314  0.123877  0.123877   55574400        0.0   \n",
       "1980-12-29  0.125622  0.126058  0.125622  0.125622   93161600        0.0   \n",
       "1980-12-30  0.123005  0.123005  0.122569  0.122569   68880000        0.0   \n",
       "1980-12-31  0.119516  0.119516  0.119080  0.119080   35750400        0.0   \n",
       "1981-01-02  0.120388  0.121260  0.120388  0.120388   21660800        0.0   \n",
       "1981-01-05  0.118207  0.118207  0.117771  0.117771   35728000        0.0   \n",
       "1981-01-06  0.112973  0.112973  0.112536  0.112536   45158400        0.0   \n",
       "1981-01-07  0.108175  0.108175  0.107739  0.107739   55686400        0.0   \n",
       "1981-01-08  0.105994  0.105994  0.105558  0.105558   39827200        0.0   \n",
       "1981-01-09  0.111228  0.111664  0.111228  0.111228   21504000        0.0   \n",
       "1981-01-12  0.111228  0.111228  0.110356  0.110356   23699200        0.0   \n",
       "\n",
       "            Stock Splits  \n",
       "Date                      \n",
       "1980-12-12           0.0  \n",
       "1980-12-15           0.0  \n",
       "1980-12-16           0.0  \n",
       "1980-12-17           0.0  \n",
       "1980-12-18           0.0  \n",
       "1980-12-19           0.0  \n",
       "1980-12-22           0.0  \n",
       "1980-12-23           0.0  \n",
       "1980-12-24           0.0  \n",
       "1980-12-26           0.0  \n",
       "1980-12-29           0.0  \n",
       "1980-12-30           0.0  \n",
       "1980-12-31           0.0  \n",
       "1981-01-02           0.0  \n",
       "1981-01-05           0.0  \n",
       "1981-01-06           0.0  \n",
       "1981-01-07           0.0  \n",
       "1981-01-08           0.0  \n",
       "1981-01-09           0.0  \n",
       "1981-01-12           0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb82924c-d1b9-44d7-bdf8-096c542aca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def subtract_days_from_date(date, days):\n",
    "    \"\"\"Subtract days from a date and return the date.\n",
    "    \n",
    "    Args: \n",
    "        date (string): Date string in YYYY-MM-DD format. \n",
    "        days (int): Number of days to subtract from date\n",
    "    \n",
    "    Returns: \n",
    "        date (date): Date in YYYY-MM-DD with X days subtracted. \n",
    "    \"\"\"\n",
    "    \n",
    "    subtracted_date = pd.to_datetime(date) - timedelta(days=days)\n",
    "    subtracted_date = subtracted_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return subtracted_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90162b5f-fd63-499a-9f36-ff8473a15265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_stockprice_at_time(day):\n",
    "    #print(day)\n",
    "    try:\n",
    "        val = hist.loc[day].Close\n",
    "    except KeyError:\n",
    "        d = subtract_days_from_date(day, 1)\n",
    "        val = get_stockprice_at_time(d)\n",
    "        \n",
    "    return round(val,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d1e593-206b-40e1-a991-7dd670171b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(sentimentPath):\n",
    "    if sentimentPath == None:\n",
    "        return None\n",
    "    else:\n",
    "        return sentimentPath[\"basic\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c68f76b-6897-4126-b59a-4c4879a90fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment(new_json[\"entities\"][0][\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1215bc-7acc-415d-99d6-5aa4df124fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b273fad0-e140-4ede-9e68-5d1599f608ba",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = pd.DataFrame(columns=[\"time_created\",\"username\",\"message\",\"sentiment\",\"derived_sentiment\",\"stock_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a03cffe1-a98b-42ce-bf7f-bf990b4382ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(new_json.shape[0]):\n",
    "    ts = new_json[\"created_at\"][i]\n",
    "    day = str(ts.year)+\"-\"+str(ts.month)+\"-\"+str(ts.day)\n",
    "    df.loc[i]= [new_json[\"created_at\"][i],new_json[\"user\"][i][\"username\"],new_json[\"body\"][i],get_sentiment(new_json[\"entities\"][i][\"sentiment\"]),None,get_stockprice_at_time(day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07682a5c-fad7-4447-a28f-d32e11646a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_created, username, message, sentiment,derived_sentiment,stock priceat that time(close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5e138e9a-6b46-4fcf-a815-645fa9910f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>username</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>derived_sentiment</th>\n",
       "      <th>stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-06 14:34:31+00:00</td>\n",
       "      <td>arya_stark</td>\n",
       "      <td>Distribution of Annual Percentage Change in $S...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-06 14:34:21+00:00</td>\n",
       "      <td>All_In_Tesla</td>\n",
       "      <td>$SPY why do we keep saying Wendy is for people...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-06 14:17:57+00:00</td>\n",
       "      <td>All_In_Tesla</td>\n",
       "      <td>$SPY this stock market send all bears back to ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06 14:00:27+00:00</td>\n",
       "      <td>LegalizeCannabisNow</td>\n",
       "      <td>$FSR $LCID $TSLA $AAPL $NIO \\nhttps://youtu.be...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-06 13:59:20+00:00</td>\n",
       "      <td>LegalizeCannabisNow</td>\n",
       "      <td>$FSR $AAPL $TSLA $LCID $NIO 🙋☕</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-11-06 13:57:52+00:00</td>\n",
       "      <td>Modest_Investor_18</td>\n",
       "      <td>@swingeveryday @Andreas2112 @RichardSimmons1 $...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-11-06 13:44:11+00:00</td>\n",
       "      <td>psatiani1982</td>\n",
       "      <td>$AAPL Markets are positioned to rally into yea...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-11-06 13:42:03+00:00</td>\n",
       "      <td>Anthony266</td>\n",
       "      <td>$AAPL fhhdsnnsnsbs</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-11-06 13:40:50+00:00</td>\n",
       "      <td>HitAHomerun</td>\n",
       "      <td>$AAPL I’ll never sell my shares…..</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-11-06 13:39:34+00:00</td>\n",
       "      <td>hoyasaxa1978</td>\n",
       "      <td>$AAPL    🍏 Finally!</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-06 13:38:00+00:00</td>\n",
       "      <td>BrownBoiler</td>\n",
       "      <td>$AAPL May be poised for a run…regardless, I wi...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-11-06 13:37:56+00:00</td>\n",
       "      <td>vxrtt</td>\n",
       "      <td>$AAPL $$$$$$$$$$BUY$$$$$$$$$$$VLTA$$$$$$$$$$$$$$$</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-11-06 13:37:31+00:00</td>\n",
       "      <td>CoastalHillbilly</td>\n",
       "      <td>$AAPL \\nPeloton threading the needle for those...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-11-06 13:36:09+00:00</td>\n",
       "      <td>Armenianheat2</td>\n",
       "      <td>$AAPL will pass all time high soon!! 💪</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-11-06 13:34:41+00:00</td>\n",
       "      <td>hoyasaxa1978</td>\n",
       "      <td>$AAPL      “Falling, like Dominos.”</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-11-06 13:22:33+00:00</td>\n",
       "      <td>StockFreedom</td>\n",
       "      <td>$FB and $AAPL need to take a good look into $G...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-11-06 13:13:07+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : A Giant Fund Bought More A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-11-06 12:51:50+00:00</td>\n",
       "      <td>Newsfilter</td>\n",
       "      <td>$AAPL $IT What’s Harder to Find Than Microchip...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-11-06 12:39:38+00:00</td>\n",
       "      <td>InsiderFinance</td>\n",
       "      <td>Top Equity activity from Smart Money daily rec...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-11-06 12:20:06+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : My 3 Biggest Stock Market ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-11-06 12:20:04+00:00</td>\n",
       "      <td>IndyM</td>\n",
       "      <td>$AAPL “Apple&amp;#39;s interest cover suggests it ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-11-06 12:15:36+00:00</td>\n",
       "      <td>InsiderFinance</td>\n",
       "      <td>Top Sweep Activity from Smart Money daily reca...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-11-06 11:55:20+00:00</td>\n",
       "      <td>potaocryptomagnificent</td>\n",
       "      <td>$AAPL Simone sign up so I can get my free shit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-11-06 11:52:25+00:00</td>\n",
       "      <td>stocklifehappylife</td>\n",
       "      <td>$AAPL \\n\\nBiden social, climate bill clears pr...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-11-06 11:39:13+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : Not Just Digital: FAANGs T...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-11-06 11:29:49+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$DIS $AAPL $AMZN  $BA $SPY  🧞‍♂️🏆</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-11-06 11:05:54+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$AMZN          $4k      $AAPL $SPY $QQQ $DIA 🧞‍♂️</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-11-06 11:04:51+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$AAPL         $180        🧞‍♂️  $SPY $AMZN</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-11-06 11:00:56+00:00</td>\n",
       "      <td>Newsfilter</td>\n",
       "      <td>A Giant Fund Bought More Apple, AMD, and Equin...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-11-06 10:58:41+00:00</td>\n",
       "      <td>looters888</td>\n",
       "      <td>$AAPL $HYLN come and help us buy more hyliion ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_created                username  \\\n",
       "0  2021-11-06 14:34:31+00:00              arya_stark   \n",
       "1  2021-11-06 14:34:21+00:00            All_In_Tesla   \n",
       "2  2021-11-06 14:17:57+00:00            All_In_Tesla   \n",
       "3  2021-11-06 14:00:27+00:00     LegalizeCannabisNow   \n",
       "4  2021-11-06 13:59:20+00:00     LegalizeCannabisNow   \n",
       "5  2021-11-06 13:57:52+00:00      Modest_Investor_18   \n",
       "6  2021-11-06 13:44:11+00:00            psatiani1982   \n",
       "7  2021-11-06 13:42:03+00:00              Anthony266   \n",
       "8  2021-11-06 13:40:50+00:00             HitAHomerun   \n",
       "9  2021-11-06 13:39:34+00:00            hoyasaxa1978   \n",
       "10 2021-11-06 13:38:00+00:00             BrownBoiler   \n",
       "11 2021-11-06 13:37:56+00:00                   vxrtt   \n",
       "12 2021-11-06 13:37:31+00:00        CoastalHillbilly   \n",
       "13 2021-11-06 13:36:09+00:00           Armenianheat2   \n",
       "14 2021-11-06 13:34:41+00:00            hoyasaxa1978   \n",
       "15 2021-11-06 13:22:33+00:00            StockFreedom   \n",
       "16 2021-11-06 13:13:07+00:00                 STCKPRO   \n",
       "17 2021-11-06 12:51:50+00:00              Newsfilter   \n",
       "18 2021-11-06 12:39:38+00:00          InsiderFinance   \n",
       "19 2021-11-06 12:20:06+00:00                 STCKPRO   \n",
       "20 2021-11-06 12:20:04+00:00                   IndyM   \n",
       "21 2021-11-06 12:15:36+00:00          InsiderFinance   \n",
       "22 2021-11-06 11:55:20+00:00  potaocryptomagnificent   \n",
       "23 2021-11-06 11:52:25+00:00      stocklifehappylife   \n",
       "24 2021-11-06 11:39:13+00:00                 STCKPRO   \n",
       "25 2021-11-06 11:29:49+00:00        StockMaster00077   \n",
       "26 2021-11-06 11:05:54+00:00        StockMaster00077   \n",
       "27 2021-11-06 11:04:51+00:00        StockMaster00077   \n",
       "28 2021-11-06 11:00:56+00:00              Newsfilter   \n",
       "29 2021-11-06 10:58:41+00:00              looters888   \n",
       "\n",
       "                                              message sentiment  \\\n",
       "0   Distribution of Annual Percentage Change in $S...      None   \n",
       "1   $SPY why do we keep saying Wendy is for people...   Bullish   \n",
       "2   $SPY this stock market send all bears back to ...   Bullish   \n",
       "3   $FSR $LCID $TSLA $AAPL $NIO \\nhttps://youtu.be...   Bullish   \n",
       "4                      $FSR $AAPL $TSLA $LCID $NIO 🙋☕   Bullish   \n",
       "5   @swingeveryday @Andreas2112 @RichardSimmons1 $...   Bullish   \n",
       "6   $AAPL Markets are positioned to rally into yea...      None   \n",
       "7                                  $AAPL fhhdsnnsnsbs      None   \n",
       "8                  $AAPL I’ll never sell my shares…..   Bullish   \n",
       "9                                 $AAPL    🍏 Finally!      None   \n",
       "10  $AAPL May be poised for a run…regardless, I wi...   Bullish   \n",
       "11  $AAPL $$$$$$$$$$BUY$$$$$$$$$$$VLTA$$$$$$$$$$$$$$$   Bullish   \n",
       "12  $AAPL \\nPeloton threading the needle for those...      None   \n",
       "13             $AAPL will pass all time high soon!! 💪   Bullish   \n",
       "14                $AAPL      “Falling, like Dominos.”      None   \n",
       "15  $FB and $AAPL need to take a good look into $G...   Bullish   \n",
       "16  $AAPL NEW ARTICLE : A Giant Fund Bought More A...      None   \n",
       "17  $AAPL $IT What’s Harder to Find Than Microchip...      None   \n",
       "18  Top Equity activity from Smart Money daily rec...      None   \n",
       "19  $AAPL NEW ARTICLE : My 3 Biggest Stock Market ...      None   \n",
       "20  $AAPL “Apple&#39;s interest cover suggests it ...   Bullish   \n",
       "21  Top Sweep Activity from Smart Money daily reca...      None   \n",
       "22  $AAPL Simone sign up so I can get my free shit...      None   \n",
       "23  $AAPL \\n\\nBiden social, climate bill clears pr...   Bullish   \n",
       "24  $AAPL NEW ARTICLE : Not Just Digital: FAANGs T...      None   \n",
       "25                  $DIS $AAPL $AMZN  $BA $SPY  🧞‍♂️🏆   Bullish   \n",
       "26  $AMZN          $4k      $AAPL $SPY $QQQ $DIA 🧞‍♂️   Bullish   \n",
       "27         $AAPL         $180        🧞‍♂️  $SPY $AMZN   Bullish   \n",
       "28  A Giant Fund Bought More Apple, AMD, and Equin...      None   \n",
       "29  $AAPL $HYLN come and help us buy more hyliion ...   Bullish   \n",
       "\n",
       "   derived_sentiment  stock_price  \n",
       "0               None      151.088  \n",
       "1               None      151.088  \n",
       "2               None      151.088  \n",
       "3               None      151.088  \n",
       "4               None      151.088  \n",
       "5               None      151.088  \n",
       "6               None      151.088  \n",
       "7               None      151.088  \n",
       "8               None      151.088  \n",
       "9               None      151.088  \n",
       "10              None      151.088  \n",
       "11              None      151.088  \n",
       "12              None      151.088  \n",
       "13              None      151.088  \n",
       "14              None      151.088  \n",
       "15              None      151.088  \n",
       "16              None      151.088  \n",
       "17              None      151.088  \n",
       "18              None      151.088  \n",
       "19              None      151.088  \n",
       "20              None      151.088  \n",
       "21              None      151.088  \n",
       "22              None      151.088  \n",
       "23              None      151.088  \n",
       "24              None      151.088  \n",
       "25              None      151.088  \n",
       "26              None      151.088  \n",
       "27              None      151.088  \n",
       "28              None      151.088  \n",
       "29              None      151.088  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1056ca12-486e-48b3-af89-b0e257104faf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-243-6244fbbdd8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sentiment\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"neutral\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mreset_indexment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'positive'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'negative'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis\n",
    "dataset = pd.read_csv('data.csv')\n",
    "dataset= dataset[dataset[\"Sentiment\"].str.contains(\"neutral\")==False]\n",
    "dataset=dataset.reset_index(drop=True)\n",
    "sentiment = {'positive': 1,'negative': 0}\n",
    "dataset.Sentiment = [sentiment[item] for item in dataset.Sentiment]\n",
    "\n",
    "dataset.head(10)\n",
    "#dataset.info()\n",
    "#dataset['Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd782854-dd0a-46a6-bed1-c5e820fe0964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Developer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#bag of words sentiment?\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "\n",
    "for i in range(0,2712):\n",
    "    review = re.sub('[^a-zA-Z]',' ',dataset['Sentence'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e7c913e1-5f48-4739-8ead-ba7bdc991c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=1500)\n",
    "x = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:,-1].values\n",
    "len(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ee1defb9-663a-418b-b137-91e1dd2cf06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train, test = train_test_split(dataset, test_size = 0.33, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.79, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f04da8b7-ff9a-4cb2-9513-f74066fd8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "767f4516-302b-436d-9026-6320e08faba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 363  325]\n",
      " [ 306 1149]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.705552963135791"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "72b008ee-49e7-4c16-957f-d1e26be92293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(msg):\n",
    "    msg_review = msg\n",
    "    msg_review = re.sub('[^a-zA-Z]',' ',msg_review)\n",
    "    msg_review = msg_review.lower()\n",
    "    msg_review = msg_review.split()\n",
    "    ps = PorterStemmer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    msg_review = [ps.stem(word) for word in msg_review if not word in set(all_stopwords)]\n",
    "    msg_review = ' '.join(msg_review)\n",
    "    user_corpus = [msg_review]\n",
    "    new_x_test = cv.transform(user_corpus).toarray()\n",
    "    new_y_pred = classifier.predict(new_x_test)\n",
    "    if new_y_pred[0] == 0:\n",
    "        return 'Bearish'\n",
    "    else:\n",
    "        return 'Bullish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "be5bedbb-0773-4baa-bc9a-31732a913bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sentiment(\"this stock is bad\")\n",
    "df.derived_sentiment = [get_sentiment(item) for item in df.message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3fc8cd44-0a92-43b0-a7ef-dbd31ac5fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0bcab71-c359-4780-ad35-99ca806c39ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-6\n",
      "2021-11-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151.088"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = df['time_created'][4]\n",
    "day = str(ts.year)+\"-\"+str(ts.month)+\"-\"+str(ts.day)\n",
    "price = get_stockprice_at_time(day)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ef5984a-4829-4ffe-a6c5-8d5205999d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150.249"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stockprice_at_time('2021-11-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f9639a6-b774-41b0-a99a-a7d6b1cea814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-11-05'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_subtraction_example = subtract_days_from_date('2021-11-06', 1)\n",
    "date_subtraction_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "419a2c88-edec-4194-9c43-f32e14a008fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_created']= pd.to_datetime(df['time_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b2d7160a-ce93-45e0-bc5b-680b00a6fe86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_created    datetime64[ns, UTC]\n",
       "username                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9f75e6d0-60a7-4098-bbd3-d132fbd49829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>username</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>derived_sentiment</th>\n",
       "      <th>stock_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-06 14:34:31+00:00</td>\n",
       "      <td>arya_stark</td>\n",
       "      <td>Distribution of Annual Percentage Change in $S...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-06 14:34:21+00:00</td>\n",
       "      <td>All_In_Tesla</td>\n",
       "      <td>$SPY why do we keep saying Wendy is for people...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-06 14:17:57+00:00</td>\n",
       "      <td>All_In_Tesla</td>\n",
       "      <td>$SPY this stock market send all bears back to ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06 14:00:27+00:00</td>\n",
       "      <td>LegalizeCannabisNow</td>\n",
       "      <td>$FSR $LCID $TSLA $AAPL $NIO \\nhttps://youtu.be...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-06 13:59:20+00:00</td>\n",
       "      <td>LegalizeCannabisNow</td>\n",
       "      <td>$FSR $AAPL $TSLA $LCID $NIO 🙋☕</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-11-06 13:57:52+00:00</td>\n",
       "      <td>Modest_Investor_18</td>\n",
       "      <td>@swingeveryday @Andreas2112 @RichardSimmons1 $...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-11-06 13:44:11+00:00</td>\n",
       "      <td>psatiani1982</td>\n",
       "      <td>$AAPL Markets are positioned to rally into yea...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-11-06 13:42:03+00:00</td>\n",
       "      <td>Anthony266</td>\n",
       "      <td>$AAPL fhhdsnnsnsbs</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-11-06 13:40:50+00:00</td>\n",
       "      <td>HitAHomerun</td>\n",
       "      <td>$AAPL I’ll never sell my shares…..</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-11-06 13:39:34+00:00</td>\n",
       "      <td>hoyasaxa1978</td>\n",
       "      <td>$AAPL    🍏 Finally!</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-11-06 13:38:00+00:00</td>\n",
       "      <td>BrownBoiler</td>\n",
       "      <td>$AAPL May be poised for a run…regardless, I wi...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-11-06 13:37:56+00:00</td>\n",
       "      <td>vxrtt</td>\n",
       "      <td>$AAPL $$$$$$$$$$BUY$$$$$$$$$$$VLTA$$$$$$$$$$$$$$$</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-11-06 13:37:31+00:00</td>\n",
       "      <td>CoastalHillbilly</td>\n",
       "      <td>$AAPL \\nPeloton threading the needle for those...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-11-06 13:36:09+00:00</td>\n",
       "      <td>Armenianheat2</td>\n",
       "      <td>$AAPL will pass all time high soon!! 💪</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-11-06 13:34:41+00:00</td>\n",
       "      <td>hoyasaxa1978</td>\n",
       "      <td>$AAPL      “Falling, like Dominos.”</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-11-06 13:22:33+00:00</td>\n",
       "      <td>StockFreedom</td>\n",
       "      <td>$FB and $AAPL need to take a good look into $G...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-11-06 13:13:07+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : A Giant Fund Bought More A...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-11-06 12:51:50+00:00</td>\n",
       "      <td>Newsfilter</td>\n",
       "      <td>$AAPL $IT What’s Harder to Find Than Microchip...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-11-06 12:39:38+00:00</td>\n",
       "      <td>InsiderFinance</td>\n",
       "      <td>Top Equity activity from Smart Money daily rec...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-11-06 12:20:06+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : My 3 Biggest Stock Market ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-11-06 12:20:04+00:00</td>\n",
       "      <td>IndyM</td>\n",
       "      <td>$AAPL “Apple&amp;#39;s interest cover suggests it ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-11-06 12:15:36+00:00</td>\n",
       "      <td>InsiderFinance</td>\n",
       "      <td>Top Sweep Activity from Smart Money daily reca...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-11-06 11:55:20+00:00</td>\n",
       "      <td>potaocryptomagnificent</td>\n",
       "      <td>$AAPL Simone sign up so I can get my free shit...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-11-06 11:52:25+00:00</td>\n",
       "      <td>stocklifehappylife</td>\n",
       "      <td>$AAPL \\n\\nBiden social, climate bill clears pr...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-11-06 11:39:13+00:00</td>\n",
       "      <td>STCKPRO</td>\n",
       "      <td>$AAPL NEW ARTICLE : Not Just Digital: FAANGs T...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-11-06 11:29:49+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$DIS $AAPL $AMZN  $BA $SPY  🧞‍♂️🏆</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-11-06 11:05:54+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$AMZN          $4k      $AAPL $SPY $QQQ $DIA 🧞‍♂️</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-11-06 11:04:51+00:00</td>\n",
       "      <td>StockMaster00077</td>\n",
       "      <td>$AAPL         $180        🧞‍♂️  $SPY $AMZN</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-11-06 11:00:56+00:00</td>\n",
       "      <td>Newsfilter</td>\n",
       "      <td>A Giant Fund Bought More Apple, AMD, and Equin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-11-06 10:58:41+00:00</td>\n",
       "      <td>looters888</td>\n",
       "      <td>$AAPL $HYLN come and help us buy more hyliion ...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>151.088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time_created                username  \\\n",
       "0  2021-11-06 14:34:31+00:00              arya_stark   \n",
       "1  2021-11-06 14:34:21+00:00            All_In_Tesla   \n",
       "2  2021-11-06 14:17:57+00:00            All_In_Tesla   \n",
       "3  2021-11-06 14:00:27+00:00     LegalizeCannabisNow   \n",
       "4  2021-11-06 13:59:20+00:00     LegalizeCannabisNow   \n",
       "5  2021-11-06 13:57:52+00:00      Modest_Investor_18   \n",
       "6  2021-11-06 13:44:11+00:00            psatiani1982   \n",
       "7  2021-11-06 13:42:03+00:00              Anthony266   \n",
       "8  2021-11-06 13:40:50+00:00             HitAHomerun   \n",
       "9  2021-11-06 13:39:34+00:00            hoyasaxa1978   \n",
       "10 2021-11-06 13:38:00+00:00             BrownBoiler   \n",
       "11 2021-11-06 13:37:56+00:00                   vxrtt   \n",
       "12 2021-11-06 13:37:31+00:00        CoastalHillbilly   \n",
       "13 2021-11-06 13:36:09+00:00           Armenianheat2   \n",
       "14 2021-11-06 13:34:41+00:00            hoyasaxa1978   \n",
       "15 2021-11-06 13:22:33+00:00            StockFreedom   \n",
       "16 2021-11-06 13:13:07+00:00                 STCKPRO   \n",
       "17 2021-11-06 12:51:50+00:00              Newsfilter   \n",
       "18 2021-11-06 12:39:38+00:00          InsiderFinance   \n",
       "19 2021-11-06 12:20:06+00:00                 STCKPRO   \n",
       "20 2021-11-06 12:20:04+00:00                   IndyM   \n",
       "21 2021-11-06 12:15:36+00:00          InsiderFinance   \n",
       "22 2021-11-06 11:55:20+00:00  potaocryptomagnificent   \n",
       "23 2021-11-06 11:52:25+00:00      stocklifehappylife   \n",
       "24 2021-11-06 11:39:13+00:00                 STCKPRO   \n",
       "25 2021-11-06 11:29:49+00:00        StockMaster00077   \n",
       "26 2021-11-06 11:05:54+00:00        StockMaster00077   \n",
       "27 2021-11-06 11:04:51+00:00        StockMaster00077   \n",
       "28 2021-11-06 11:00:56+00:00              Newsfilter   \n",
       "29 2021-11-06 10:58:41+00:00              looters888   \n",
       "\n",
       "                                              message sentiment  \\\n",
       "0   Distribution of Annual Percentage Change in $S...      None   \n",
       "1   $SPY why do we keep saying Wendy is for people...   Bullish   \n",
       "2   $SPY this stock market send all bears back to ...   Bullish   \n",
       "3   $FSR $LCID $TSLA $AAPL $NIO \\nhttps://youtu.be...   Bullish   \n",
       "4                      $FSR $AAPL $TSLA $LCID $NIO 🙋☕   Bullish   \n",
       "5   @swingeveryday @Andreas2112 @RichardSimmons1 $...   Bullish   \n",
       "6   $AAPL Markets are positioned to rally into yea...      None   \n",
       "7                                  $AAPL fhhdsnnsnsbs      None   \n",
       "8                  $AAPL I’ll never sell my shares…..   Bullish   \n",
       "9                                 $AAPL    🍏 Finally!      None   \n",
       "10  $AAPL May be poised for a run…regardless, I wi...   Bullish   \n",
       "11  $AAPL $$$$$$$$$$BUY$$$$$$$$$$$VLTA$$$$$$$$$$$$$$$   Bullish   \n",
       "12  $AAPL \\nPeloton threading the needle for those...      None   \n",
       "13             $AAPL will pass all time high soon!! 💪   Bullish   \n",
       "14                $AAPL      “Falling, like Dominos.”      None   \n",
       "15  $FB and $AAPL need to take a good look into $G...   Bullish   \n",
       "16  $AAPL NEW ARTICLE : A Giant Fund Bought More A...      None   \n",
       "17  $AAPL $IT What’s Harder to Find Than Microchip...      None   \n",
       "18  Top Equity activity from Smart Money daily rec...      None   \n",
       "19  $AAPL NEW ARTICLE : My 3 Biggest Stock Market ...      None   \n",
       "20  $AAPL “Apple&#39;s interest cover suggests it ...   Bullish   \n",
       "21  Top Sweep Activity from Smart Money daily reca...      None   \n",
       "22  $AAPL Simone sign up so I can get my free shit...      None   \n",
       "23  $AAPL \\n\\nBiden social, climate bill clears pr...   Bullish   \n",
       "24  $AAPL NEW ARTICLE : Not Just Digital: FAANGs T...      None   \n",
       "25                  $DIS $AAPL $AMZN  $BA $SPY  🧞‍♂️🏆   Bullish   \n",
       "26  $AMZN          $4k      $AAPL $SPY $QQQ $DIA 🧞‍♂️   Bullish   \n",
       "27         $AAPL         $180        🧞‍♂️  $SPY $AMZN   Bullish   \n",
       "28  A Giant Fund Bought More Apple, AMD, and Equin...      None   \n",
       "29  $AAPL $HYLN come and help us buy more hyliion ...   Bullish   \n",
       "\n",
       "   derived_sentiment  stock_price  \n",
       "0            Bullish      151.088  \n",
       "1            Bullish      151.088  \n",
       "2            Bullish      151.088  \n",
       "3            Bearish      151.088  \n",
       "4            Bearish      151.088  \n",
       "5            Bearish      151.088  \n",
       "6            Bearish      151.088  \n",
       "7            Bearish      151.088  \n",
       "8            Bearish      151.088  \n",
       "9            Bearish      151.088  \n",
       "10           Bullish      151.088  \n",
       "11           Bearish      151.088  \n",
       "12           Bearish      151.088  \n",
       "13           Bearish      151.088  \n",
       "14           Bearish      151.088  \n",
       "15           Bearish      151.088  \n",
       "16           Bullish      151.088  \n",
       "17           Bullish      151.088  \n",
       "18           Bearish      151.088  \n",
       "19           Bullish      151.088  \n",
       "20           Bullish      151.088  \n",
       "21           Bearish      151.088  \n",
       "22           Bullish      151.088  \n",
       "23           Bullish      151.088  \n",
       "24           Bullish      151.088  \n",
       "25           Bullish      151.088  \n",
       "26           Bullish      151.088  \n",
       "27           Bullish      151.088  \n",
       "28           Bullish      151.088  \n",
       "29           Bullish      151.088  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29f993-eccb-4077-a220-3d8d04dbd15a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
